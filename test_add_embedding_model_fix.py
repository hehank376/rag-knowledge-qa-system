#!/usr/bin/env python3
"""
æ·»åŠ åµŒå…¥æ¨¡å‹åŠŸèƒ½æµ‹è¯•

æµ‹è¯•å‰ç«¯addEmbeddingModelæ–¹æ³•æ˜¯å¦æ­£ç¡®ä¼ é€’ç»´åº¦å‚æ•°åˆ°åç«¯
"""

import asyncio
import sys
import json
import yaml
from pathlib import Path
import aiohttp

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))


def print_section(title: str):
    """æ‰“å°æ ¼å¼åŒ–çš„ç« èŠ‚"""
    print(f"\n{'='*50}")
    print(f"ğŸ” {title}")
    print(f"{'='*50}")


async def test_add_embedding_model_api():
    """æµ‹è¯•æ·»åŠ åµŒå…¥æ¨¡å‹API"""
    print_section("æµ‹è¯•æ·»åŠ åµŒå…¥æ¨¡å‹API")
    
    base_url = "http://localhost:8000"
    
    # æ¨¡æ‹Ÿå‰ç«¯addEmbeddingModelå‡½æ•°æ„é€ çš„æ•°æ®
    print("1. æ¨¡æ‹Ÿå‰ç«¯addEmbeddingModelæ•°æ®æ„é€ ")
    
    # æ¨¡æ‹Ÿå‰ç«¯è¡¨å•æ•°æ®
    form_data = {
        'modelProvider': 'siliconflow',
        'embeddingModel': 'BAAI/bge-large-zh-v1.5',
        'embeddingDimension': '2048',  # è¿™æ˜¯å…³é”®çš„ç»´åº¦å‚æ•°
        'embeddingBatchSize': '50',
        'chunkSize': '1000',
        'chunkOverlap': '50',
        'embeddingTimeout': '120',
        'modelApiKey': 'sk-test-embedding-123',
        'modelBaseUrl': 'https://api.siliconflow.cn/v1'
    }
    
    # æ¨¡æ‹Ÿå‰ç«¯addEmbeddingModelå‡½æ•°çš„é€»è¾‘
    provider = form_data['modelProvider']
    modelName = form_data['embeddingModel']
    dimensions = int(form_data['embeddingDimension'])
    batchSize = int(form_data['embeddingBatchSize'])
    chunkSize = int(form_data['chunkSize'])
    chunk_overlap = int(form_data['chunkOverlap'])
    embeddingTimeout = float(form_data['embeddingTimeout'])
    
    # æ„é€ configå¯¹è±¡ï¼ˆå‰ç«¯addEmbeddingModelå‡½æ•°ä¸­çš„configï¼‰
    config = {
        'name': f"{provider}_{modelName.replace('/', '_').replace('-', '_')}",
        'provider': provider,
        'model_name': modelName,
        'config': {
            'batch_size': batchSize,
            'dimensions': dimensions,  # å…³é”®ï¼šç»´åº¦å‚æ•°
            'chunk_size': chunkSize,
            'chunk_overlap': chunk_overlap,
            'timeout': embeddingTimeout,
            'api_key': form_data['modelApiKey'],
            'base_url': form_data['modelBaseUrl']
        },
        'enabled': True,
        'priority': 5
    }
    
    print(f"   ğŸ“‹ æ„é€ çš„configå¯¹è±¡:")
    print(f"      name: {config['name']}")
    print(f"      provider: {config['provider']}")
    print(f"      model_name: {config['model_name']}")
    print(f"      config.dimensions: {config['config']['dimensions']} ({type(config['config']['dimensions']).__name__})")
    print(f"      config.batch_size: {config['config']['batch_size']}")
    print(f"      config.chunk_size: {config['config']['chunk_size']}")
    
    # 2. æ¨¡æ‹Ÿä¿®å¤åçš„modelManager.addModelæ–¹æ³•
    print("\n2. æ¨¡æ‹Ÿä¿®å¤åçš„modelManager.addModelæ–¹æ³•")
    modelType = 'embedding'
    
    # æ„é€ åç«¯APIæœŸæœ›çš„æ•°æ®æ ¼å¼ï¼ˆä¿®å¤åçš„é€»è¾‘ï¼‰
    modelData = {
        'model_type': modelType,
        'name': config['name'],
        'provider': config['provider'],
        'model_name': config['model_name'],
        'config': config['config']
    }
    
    print(f"   ğŸ“¤ å‘é€åˆ°åç«¯çš„modelData:")
    print(f"      model_type: {modelData['model_type']}")
    print(f"      name: {modelData['name']}")
    print(f"      provider: {modelData['provider']}")
    print(f"      model_name: {modelData['model_name']}")
    print(f"      config.dimensions: {modelData['config']['dimensions']}")
    print(f"      config.api_key: {modelData['config']['api_key'][:10]}...")
    
    # 3. å‘é€APIè¯·æ±‚
    print("\n3. å‘é€æ·»åŠ æ¨¡å‹APIè¯·æ±‚")
    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(
                f"{base_url}/models/add",
                json=modelData,
                headers={"Content-Type": "application/json"}
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    print(f"   âœ… æ·»åŠ æ¨¡å‹æˆåŠŸ")
                    print(f"   ğŸ“‹ å“åº”: {result}")
                    return True
                else:
                    error_text = await response.text()
                    print(f"   âŒ æ·»åŠ æ¨¡å‹å¤±è´¥ (çŠ¶æ€ç : {response.status})")
                    print(f"   ğŸ“‹ é”™è¯¯: {error_text}")
                    return False
                    
    except Exception as e:
        print(f"   âŒ è¯·æ±‚å¤±è´¥: {str(e)}")
        print(f"   ğŸ’¡ è¯·ç¡®ä¿åç«¯æœåŠ¡æ­£åœ¨è¿è¡Œ: python -m rag_system.api.main")
        return False


async def test_get_model_configs():
    """æµ‹è¯•è·å–æ¨¡å‹é…ç½®"""
    print_section("æµ‹è¯•è·å–æ¨¡å‹é…ç½®")
    
    base_url = "http://localhost:8000"
    
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(f"{base_url}/models/configs") as response:
                if response.status == 200:
                    result = await response.json()
                    print(f"   âœ… è·å–æ¨¡å‹é…ç½®æˆåŠŸ")
                    
                    model_configs = result.get('model_configs', {})
                    print(f"   ğŸ“‹ æ¨¡å‹é…ç½®æ•°é‡: {len(model_configs)}")
                    
                    # æŸ¥æ‰¾æˆ‘ä»¬åˆšæ·»åŠ çš„åµŒå…¥æ¨¡å‹
                    embedding_models = [
                        config for config in model_configs.values() 
                        if config.get('model_type') == 'embedding'
                    ]
                    
                    print(f"   ğŸ“‹ åµŒå…¥æ¨¡å‹æ•°é‡: {len(embedding_models)}")
                    
                    for model in embedding_models:
                        print(f"      æ¨¡å‹: {model.get('name', 'unknown')}")
                        print(f"      æä¾›å•†: {model.get('provider', 'unknown')}")
                        print(f"      ç»´åº¦: {model.get('config', {}).get('dimensions', 'unknown')}")
                    
                    return len(embedding_models) > 0
                else:
                    error_text = await response.text()
                    print(f"   âŒ è·å–æ¨¡å‹é…ç½®å¤±è´¥ (çŠ¶æ€ç : {response.status})")
                    print(f"   ğŸ“‹ é”™è¯¯: {error_text}")
                    return False
                    
    except Exception as e:
        print(f"   âŒ è¯·æ±‚å¤±è´¥: {str(e)}")
        return False


def test_frontend_data_flow():
    """æµ‹è¯•å‰ç«¯æ•°æ®æµ"""
    print_section("æµ‹è¯•å‰ç«¯æ•°æ®æµ")
    
    print("1. æ¨¡æ‹Ÿå‰ç«¯è¡¨å•è¾“å…¥")
    # æ¨¡æ‹Ÿç”¨æˆ·åœ¨å‰ç«¯è¾“å…¥çš„æ•°æ®
    user_input = {
        'embeddingDimension': '2048',  # ç”¨æˆ·è¾“å…¥çš„ç»´åº¦
        'embeddingModel': 'BAAI/bge-large-zh-v1.5',
        'modelProvider': 'siliconflow'
    }
    
    print(f"   ğŸ‘¤ ç”¨æˆ·è¾“å…¥ç»´åº¦: {user_input['embeddingDimension']}")
    
    print("\n2. å‰ç«¯JavaScriptå¤„ç†")
    # æ¨¡æ‹Ÿå‰ç«¯JavaScriptçš„parseIntå¤„ç†
    dimensions = int(user_input['embeddingDimension']) if user_input['embeddingDimension'] else 1024
    print(f"   ğŸ”§ JavaScriptå¤„ç†å: {dimensions} ({type(dimensions).__name__})")
    
    print("\n3. æ„é€ configå¯¹è±¡")
    config = {
        'config': {
            'dimensions': dimensions,
            'batch_size': 50,
            'chunk_size': 1000
        }
    }
    print(f"   ğŸ“¦ config.dimensions: {config['config']['dimensions']} ({type(config['config']['dimensions']).__name__})")
    
    print("\n4. æ„é€ APIè¯·æ±‚æ•°æ®")
    modelData = {
        'model_type': 'embedding',
        'config': config['config']
    }
    print(f"   ğŸ“¤ APIè¯·æ±‚ä¸­çš„dimensions: {modelData['config']['dimensions']} ({type(modelData['config']['dimensions']).__name__})")
    
    # éªŒè¯æ•°æ®ç±»å‹
    if isinstance(modelData['config']['dimensions'], int) and modelData['config']['dimensions'] > 0:
        print(f"   âœ… ç»´åº¦å‚æ•°æ ¼å¼æ­£ç¡®")
        return True
    else:
        print(f"   âŒ ç»´åº¦å‚æ•°æ ¼å¼é”™è¯¯")
        return False


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æ·»åŠ åµŒå…¥æ¨¡å‹åŠŸèƒ½æµ‹è¯•")
    print("æµ‹è¯•å‰ç«¯addEmbeddingModelæ–¹æ³•æ˜¯å¦æ­£ç¡®ä¼ é€’ç»´åº¦å‚æ•°åˆ°åç«¯")
    
    results = []
    
    try:
        # 1. æµ‹è¯•å‰ç«¯æ•°æ®æµ
        results.append(test_frontend_data_flow())
        
        # 2. æµ‹è¯•æ·»åŠ åµŒå…¥æ¨¡å‹API
        results.append(await test_add_embedding_model_api())
        
        # 3. æµ‹è¯•è·å–æ¨¡å‹é…ç½®
        results.append(await test_get_model_configs())
        
        print_section("æµ‹è¯•æ€»ç»“")
        
        if all(results):
            print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
            print("ğŸ¯ æ·»åŠ åµŒå…¥æ¨¡å‹åŠŸèƒ½æ­£å¸¸å·¥ä½œ:")
            print("   - å‰ç«¯æ•°æ®æµ: æ­£ç¡®å¤„ç†ç»´åº¦å‚æ•°")
            print("   - APIè¯·æ±‚æ ¼å¼: ç¬¦åˆåç«¯æœŸæœ›")
            print("   - æ¨¡å‹æ·»åŠ : æˆåŠŸä¿å­˜åˆ°ç³»ç»Ÿ")
            print("   - é…ç½®è·å–: å¯ä»¥æ­£ç¡®æ£€ç´¢")
            
            print("\nğŸ’¡ ä¿®å¤è¦ç‚¹:")
            print("   1. modelManager.addModel ç°åœ¨æ­£ç¡®æ„é€ APIè¯·æ±‚æ•°æ®")
            print("   2. ç»´åº¦å‚æ•°æ­£ç¡®ä¼ é€’åˆ°åç«¯")
            print("   3. åç«¯APIæ­£ç¡®å¤„ç†åµŒå…¥æ¨¡å‹é…ç½®")
            print("   4. å‰åç«¯æ•°æ®æ ¼å¼å®Œå…¨åŒ¹é…")
            
        else:
            print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
            failed_tests = []
            if not results[0]: failed_tests.append("å‰ç«¯æ•°æ®æµ")
            if not results[1]: failed_tests.append("æ·»åŠ æ¨¡å‹API")
            if not results[2]: failed_tests.append("è·å–æ¨¡å‹é…ç½®")
            
            print(f"   å¤±è´¥çš„æµ‹è¯•: {', '.join(failed_tests)}")
            print("   è¯·æ£€æŸ¥:")
            print("   - åç«¯æœåŠ¡æ˜¯å¦æ­£åœ¨è¿è¡Œ")
            print("   - APIç«¯ç‚¹æ˜¯å¦æ­£ç¡®å®ç°")
            print("   - å‰ç«¯JavaScriptæ˜¯å¦æ­£ç¡®ä¿®å¤")
        
        return all(results)
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)