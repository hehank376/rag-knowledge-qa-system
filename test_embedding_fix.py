#!/usr/bin/env python3
"""
测试嵌入修复
"""
import asyncio
import requests
import time
from pathlib import Path

def create_very_large_test_document():
    """创建一个非常大的文档用于测试"""
    content = """
# 深度学习与人工智能技术全面解析

## 引言
人工智能（Artificial Intelligence，AI）作为21世纪最具革命性的技术之一，正在深刻改变着我们的生活方式、工作模式和社会结构。从早期的符号主义AI到现代的深度学习，人工智能技术经历了多次重大突破和发展。本文将全面解析深度学习与人工智能技术的核心概念、发展历程、技术架构、应用场景以及未来发展趋势。

## 第一章：人工智能发展历程

### 1.1 早期发展阶段（1950-1980年代）
人工智能的概念最早可以追溯到1950年，当时英国数学家阿兰·图灵提出了著名的"图灵测试"，为判断机器是否具有智能提供了一个标准。在这个阶段，研究者们主要关注符号推理、专家系统和知识表示等领域。

专家系统是这一时期的重要成果，它通过将人类专家的知识编码到计算机程序中，使计算机能够在特定领域内进行推理和决策。然而，由于知识获取的困难性和推理能力的局限性，专家系统的应用范围相对有限。

### 1.2 机器学习兴起（1980-2000年代）
随着计算能力的提升和数据量的增加，机器学习逐渐成为人工智能研究的主流方向。这一时期出现了许多重要的机器学习算法，包括决策树、支持向量机、神经网络等。

神经网络虽然在1980年代就已经出现，但由于计算资源的限制和训练算法的不成熟，其发展一度陷入低谷。直到反向传播算法的提出和完善，神经网络才重新获得关注。

### 1.3 深度学习革命（2000年代至今）
2006年，Geoffrey Hinton等研究者提出了深度信念网络（Deep Belief Networks），标志着深度学习时代的开始。深度学习通过构建多层神经网络，能够自动学习数据的层次化特征表示，在图像识别、语音识别、自然语言处理等领域取得了突破性进展。

2012年，AlexNet在ImageNet图像识别竞赛中的胜利，进一步证明了深度学习的强大能力。此后，深度学习技术快速发展，出现了ResNet、Transformer、BERT、GPT等一系列重要模型。

## 第二章：深度学习核心技术

### 2.1 神经网络基础
神经网络是深度学习的基础，它模拟了人脑神经元的工作原理。一个基本的神经网络由输入层、隐藏层和输出层组成，每一层包含多个神经元（节点），神经元之间通过权重连接。

神经网络的学习过程主要包括前向传播和反向传播两个阶段。在前向传播中，输入数据通过网络层层传递，最终产生输出结果。在反向传播中，网络根据输出结果与真实标签之间的误差，调整各层的权重参数。

### 2.2 卷积神经网络（CNN）
卷积神经网络是专门用于处理具有网格结构数据（如图像）的深度学习模型。CNN通过卷积操作、池化操作和全连接层的组合，能够有效提取图像的局部特征和全局特征。

卷积层是CNN的核心组件，它使用可学习的滤波器（卷积核）在输入数据上进行卷积操作，提取不同的特征。池化层则用于降低特征图的空间维度，减少计算量并提高模型的鲁棒性。

### 2.3 循环神经网络（RNN）
循环神经网络是专门用于处理序列数据的深度学习模型。与传统的前馈神经网络不同，RNN具有记忆能力，能够处理变长的序列输入。

然而，传统的RNN存在梯度消失和梯度爆炸问题，限制了其在长序列处理中的应用。为了解决这些问题，研究者们提出了长短期记忆网络（LSTM）和门控循环单元（GRU）等改进模型。

### 2.4 Transformer架构
Transformer是近年来最重要的深度学习架构之一，它完全基于注意力机制，摒弃了传统的循环和卷积结构。Transformer在自然语言处理领域取得了巨大成功，成为了BERT、GPT等大型语言模型的基础架构。

注意力机制是Transformer的核心，它允许模型在处理序列中的每个位置时，都能够关注到序列中的所有其他位置，从而更好地捕捉长距离依赖关系。

## 第三章：自然语言处理技术

### 3.1 文本预处理
文本预处理是自然语言处理的第一步，包括分词、词性标注、命名实体识别、句法分析等任务。对于中文文本，分词是一个特别重要的步骤，因为中文没有明显的词边界标记。

现代的文本预处理通常使用深度学习模型，如基于BERT的分词器，能够更好地处理歧义和未登录词问题。

### 3.2 词向量表示
词向量是将词汇映射到连续向量空间的技术，使得语义相似的词在向量空间中距离较近。早期的词向量方法包括Word2Vec、GloVe等，这些方法为每个词学习一个固定的向量表示。

然而，固定的词向量无法处理一词多义的问题。为了解决这个问题，研究者们提出了上下文相关的词向量表示方法，如ELMo、BERT等。

### 3.3 语言模型
语言模型是自然语言处理的核心技术之一，它用于建模文本序列的概率分布。传统的语言模型基于n-gram统计方法，而现代的语言模型则基于深度学习技术。

大型语言模型（Large Language Models，LLMs）如GPT系列、BERT系列等，通过在大规模文本语料上进行预训练，学习到了丰富的语言知识和世界知识，在各种自然语言处理任务中表现出色。

### 3.4 机器翻译
机器翻译是将一种语言的文本自动翻译成另一种语言的技术。早期的机器翻译方法基于规则和统计方法，而现代的机器翻译则主要基于神经网络技术。

神经机器翻译（Neural Machine Translation，NMT）使用编码器-解码器架构，能够端到端地学习翻译模型。Transformer架构的引入进一步提升了机器翻译的质量和效率。

## 第四章：计算机视觉技术

### 4.1 图像分类
图像分类是计算机视觉的基础任务，目标是将输入图像分配到预定义的类别中。深度学习在图像分类任务中取得了巨大成功，特别是卷积神经网络的应用。

从AlexNet到ResNet，再到EfficientNet，图像分类模型的准确率不断提升。这些模型不仅在学术数据集上表现出色，也在实际应用中发挥了重要作用。

### 4.2 目标检测
目标检测不仅要识别图像中的对象类别，还要定位对象的位置。现代的目标检测方法主要分为两类：两阶段检测器（如R-CNN系列）和单阶段检测器（如YOLO系列）。

两阶段检测器首先生成候选区域，然后对每个候选区域进行分类和位置回归。单阶段检测器则直接在特征图上预测对象的类别和位置，具有更快的检测速度。

### 4.3 语义分割
语义分割是像素级别的分类任务，需要为图像中的每个像素分配一个语义标签。全卷积网络（FCN）是语义分割的重要里程碑，它将传统的分类网络改造为能够输出密集预测的网络。

U-Net、DeepLab等模型进一步改进了语义分割的性能，在医学图像分析、自动驾驶等领域得到了广泛应用。

### 4.4 生成对抗网络（GAN）
生成对抗网络是一种生成模型，由生成器和判别器两个网络组成。生成器试图生成逼真的假数据，而判别器试图区分真实数据和生成数据。通过对抗训练，生成器能够学习到数据的分布。

GAN在图像生成、图像编辑、数据增强等方面有着广泛的应用。StyleGAN、BigGAN等模型能够生成高质量的图像，甚至达到了以假乱真的程度。

## 第五章：强化学习

### 5.1 强化学习基础
强化学习是机器学习的一个重要分支，它研究智能体如何在环境中通过试错学习最优策略。强化学习的核心概念包括状态、动作、奖励、策略等。

与监督学习不同，强化学习没有明确的标签数据，智能体需要通过与环境的交互来学习。这种学习方式更接近人类和动物的学习过程。

### 5.2 深度强化学习
深度强化学习结合了深度学习和强化学习的优势，使用深度神经网络来近似价值函数或策略函数。DQN（Deep Q-Network）是深度强化学习的重要里程碑，它使用卷积神经网络来学习Q函数。

Actor-Critic方法是另一类重要的深度强化学习算法，它同时学习策略函数（Actor）和价值函数（Critic）。PPO、A3C等算法在这一框架下取得了很好的效果。

### 5.3 多智能体强化学习
多智能体强化学习研究多个智能体在共同环境中的学习和交互。这种设置更接近现实世界的复杂场景，但也带来了新的挑战，如非平稳性、部分可观测性等。

自博弈（Self-play）是多智能体强化学习的重要技术，通过让智能体与自己的历史版本对战，能够不断提升策略的水平。AlphaGo、OpenAI Five等系统都采用了这种方法。

## 第六章：应用场景与案例分析

### 6.1 智能客服系统
智能客服系统是人工智能技术在商业领域的重要应用之一。现代的智能客服系统结合了自然语言理解、对话管理、知识图谱等多种技术，能够理解用户的意图并提供相应的服务。

基于深度学习的对话系统能够处理更复杂的对话场景，提供更自然的交互体验。一些先进的系统甚至能够进行多轮对话，记住上下文信息。

### 6.2 推荐系统
推荐系统旨在为用户推荐可能感兴趣的内容或商品。传统的推荐系统主要基于协同过滤和内容过滤方法，而现代的推荐系统则广泛采用深度学习技术。

深度学习能够更好地建模用户和物品的复杂关系，处理稀疏数据问题，并融合多种类型的特征。神经协同过滤、深度因子分解机等模型在推荐系统中得到了广泛应用。

### 6.3 自动驾驶
自动驾驶是人工智能技术的综合应用，涉及计算机视觉、传感器融合、路径规划、决策控制等多个方面。深度学习在感知模块中发挥了重要作用，能够识别道路、车辆、行人等各种对象。

端到端的自动驾驶方法直接从传感器数据学习驾驶策略，而模块化的方法则将自动驾驶分解为多个子任务。两种方法各有优劣，目前仍在不断发展中。

### 6.4 医疗诊断
人工智能在医疗诊断领域展现出巨大潜力，特别是在医学影像分析方面。深度学习模型能够从X光片、CT扫描、MRI图像中识别病变，辅助医生进行诊断。

一些研究表明，AI系统在某些特定疾病的诊断准确率甚至超过了人类专家。然而，医疗AI的应用还面临着数据隐私、监管审批、临床验证等挑战。

## 第七章：技术挑战与解决方案

### 7.1 数据质量与标注
高质量的数据是深度学习成功的关键，但获取大量标注数据往往成本高昂且耗时。为了解决这个问题，研究者们提出了多种方法，包括数据增强、迁移学习、半监督学习、自监督学习等。

数据增强通过对原始数据进行变换来扩充训练集，迁移学习利用预训练模型的知识来减少对标注数据的需求，半监督学习和自监督学习则能够利用未标注数据进行学习。

### 7.2 模型可解释性
深度学习模型通常被认为是"黑盒"，其决策过程难以理解和解释。这在一些关键应用领域（如医疗、金融）中是不可接受的。为了提高模型的可解释性，研究者们提出了多种方法。

注意力机制、梯度分析、特征可视化等技术能够帮助理解模型的决策过程。此外，一些研究致力于开发本质上更可解释的模型架构。

### 7.3 计算资源需求
大型深度学习模型的训练和推理需要大量的计算资源，这限制了技术的普及和应用。为了降低计算需求，研究者们提出了模型压缩、知识蒸馏、量化等技术。

模型压缩通过剪枝、低秩分解等方法减少模型参数，知识蒸馏将大模型的知识转移到小模型中，量化则通过降低数值精度来减少存储和计算需求。

### 7.4 鲁棒性与安全性
深度学习模型容易受到对抗样本的攻击，即通过在输入中添加微小的扰动来欺骗模型。这种脆弱性在安全关键的应用中是不可接受的。

对抗训练、防御蒸馏、输入变换等方法被提出来提高模型的鲁棒性。此外，研究者们也在探索从理论角度理解和解决对抗样本问题。

## 第八章：未来发展趋势

### 8.1 大型语言模型的发展
大型语言模型（LLMs）如GPT系列、PaLM、ChatGPT等展现出了惊人的能力，能够进行对话、写作、编程、推理等多种任务。未来的发展趋势包括模型规模的进一步扩大、多模态能力的增强、以及更好的对齐和控制。

### 8.2 多模态人工智能
未来的AI系统将能够同时处理文本、图像、音频、视频等多种模态的信息，实现更全面的理解和交互。CLIP、DALL-E、GPT-4V等模型已经展现了多模态AI的潜力。

### 8.3 具身智能
具身智能强调AI系统与物理世界的交互，通过机器人等载体来实现智能行为。这需要结合感知、规划、控制等多个方面的技术，是实现通用人工智能的重要途径。

### 8.4 神经符号结合
神经网络擅长模式识别和学习，而符号系统擅长逻辑推理和知识表示。未来的AI系统可能会更好地结合这两种方法的优势，实现更强的推理和泛化能力。

## 结论

人工智能技术正在快速发展，深度学习作为其核心驱动力，在各个领域都取得了显著进展。从计算机视觉到自然语言处理，从强化学习到多模态AI，技术的边界不断被推进。

然而，我们也面临着诸多挑战，包括数据质量、模型可解释性、计算资源需求、鲁棒性和安全性等。解决这些挑战需要学术界和工业界的共同努力。

展望未来，人工智能技术将继续向着更加智能、更加通用、更加安全的方向发展。大型语言模型、多模态AI、具身智能、神经符号结合等技术趋势将推动AI技术的进一步突破。

我们有理由相信，在不久的将来，人工智能将在更多领域发挥重要作用，为人类社会带来更大的价值和福祉。同时，我们也需要关注AI技术发展带来的伦理、社会和经济影响，确保技术的发展能够造福全人类。

人工智能的未来充满无限可能，让我们共同期待这个激动人心的技术革命继续展开。
"""
    # 重复内容以创建更大的文档（约10倍大小）
    large_content = content * 10  # 创建约10倍大小的文档
    test_file = Path("very_large_test_document.txt")
    test_file.write_text(large_content, encoding='utf-8')
    return test_file, len(large_content)

def test_very_large_document_upload():
    """测试非常大的文档上传"""
    print("🧪 测试非常大文档处理...")
    
    # 创建非常大的文档
    test_file, content_size = create_very_large_test_document()
    print(f"📄 创建测试文档: {test_file.name}")
    print(f"📏 文档大小: {content_size:,} 字符")
    
    try:
        # 上传文档
        print("📤 上传文档...")
        with open(test_file, 'rb') as f:
            files = {'file': (test_file.name, f, 'text/plain')}
            response = requests.post("http://localhost:8000/documents/upload", files=files)
        
        if response.status_code == 200:
            result = response.json()
            document_id = result.get('document_id')
            print(f"✅ 文档上传成功")
            print(f"   文档ID: {document_id}")
            print(f"   状态: {result.get('status')}")
            
            # 等待处理完成
            print("⏳ 等待文档处理...")
            max_wait = 600  # 最多等待10分钟
            wait_time = 0
            
            while wait_time < max_wait:
                time.sleep(10)  # 增加等待间隔
                wait_time += 10
                
                # 检查处理状态
                doc_response = requests.get(f"http://localhost:8000/documents/{document_id}")
                if doc_response.status_code == 200:
                    doc_data = doc_response.json()
                    status = doc_data.get('status')
                    print(f"   状态: {status} (等待时间: {wait_time}s)")
                    
                    if status == 'ready':
                        print("✅ 文档处理完成")
                        print(f"   文本块数: {doc_data.get('chunk_count', 0)}")
                        print(f"   向量数: {doc_data.get('vector_count', 0)}")
                        
                        # 测试查询
                        print("🔍 测试查询功能...")
                        query_data = {
                            "query": "什么是深度学习？",
                            "top_k": 3
                        }
                        query_response = requests.post("http://localhost:8000/qa/query", json=query_data)
                        if query_response.status_code == 200:
                            query_result = query_response.json()
                            print(f"✅ 查询成功")
                            print(f"   找到 {len(query_result.get('results', []))} 个相关结果")
                            if query_result.get('results'):
                                print(f"   最高相似度: {query_result['results'][0].get('similarity', 0):.3f}")
                        else:
                            print(f"❌ 查询失败: {query_response.status_code}")
                        
                        break
                    elif status == 'error':
                        print("❌ 文档处理失败")
                        print(f"   错误信息: {doc_data.get('error_message', 'Unknown error')}")
                        break
                else:
                    print(f"⚠️ 无法获取文档状态: {doc_response.status_code}")
            
            if wait_time >= max_wait:
                print("⏰ 等待超时")
                
        else:
            print(f"❌ 文档上传失败: {response.status_code}")
            print(f"   响应: {response.text}")
            
    except Exception as e:
        print(f"❌ 测试失败: {e}")
    finally:
        # 清理测试文件
        if test_file.exists():
            test_file.unlink()
            print(f"🗑️ 清理测试文件: {test_file.name}")

def main():
    """主函数"""
    print("🚀 开始非常大文档处理测试")
    print("=" * 60)
    test_very_large_document_upload()
    print("=" * 60)
    print("✅ 测试完成")

if __name__ == "__main__":
    main()