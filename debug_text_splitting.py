#!/usr/bin/env python3
"""
è°ƒè¯•æ–‡æœ¬åˆ†å‰²é—®é¢˜
"""
import asyncio
from rag_system.document_processing.splitters import RecursiveTextSplitter, SplitConfig
from rag_system.document_processing.preprocessors import TextPreprocessor, PreprocessConfig

def test_text_splitting():
    """æµ‹è¯•æ–‡æœ¬åˆ†å‰²"""
    print("ğŸ” è°ƒè¯•æ–‡æœ¬åˆ†å‰²é—®é¢˜...")
    
    # åˆ›å»ºæµ‹è¯•æ–‡æœ¬
    test_text = """
# æ·±åº¦å­¦ä¹ ä¸äººå·¥æ™ºèƒ½æŠ€æœ¯å…¨é¢è§£æ

## å¼•è¨€
äººå·¥æ™ºèƒ½ï¼ˆArtificial Intelligenceï¼ŒAIï¼‰ä½œä¸º21ä¸–çºªæœ€å…·é©å‘½æ€§çš„æŠ€æœ¯ä¹‹ä¸€ï¼Œæ­£åœ¨æ·±åˆ»æ”¹å˜ç€æˆ‘ä»¬çš„ç”Ÿæ´»æ–¹å¼ã€å·¥ä½œæ¨¡å¼å’Œç¤¾ä¼šç»“æ„ã€‚

## ç¬¬ä¸€ç« ï¼šäººå·¥æ™ºèƒ½å‘å±•å†ç¨‹

### 1.1 æ—©æœŸå‘å±•é˜¶æ®µï¼ˆ1950-1980å¹´ä»£ï¼‰
äººå·¥æ™ºèƒ½çš„æ¦‚å¿µæœ€æ—©å¯ä»¥è¿½æº¯åˆ°1950å¹´ï¼Œå½“æ—¶è‹±å›½æ•°å­¦å®¶é˜¿å…°Â·å›¾çµæå‡ºäº†è‘—åçš„"å›¾çµæµ‹è¯•"ã€‚

### 1.2 æœºå™¨å­¦ä¹ å…´èµ·ï¼ˆ1980-2000å¹´ä»£ï¼‰
éšç€è®¡ç®—èƒ½åŠ›çš„æå‡å’Œæ•°æ®é‡çš„å¢åŠ ï¼Œæœºå™¨å­¦ä¹ é€æ¸æˆä¸ºäººå·¥æ™ºèƒ½ç ”ç©¶çš„ä¸»æµæ–¹å‘ã€‚

## ç¬¬äºŒç« ï¼šæ·±åº¦å­¦ä¹ æ ¸å¿ƒæŠ€æœ¯

### 2.1 ç¥ç»ç½‘ç»œåŸºç¡€
ç¥ç»ç½‘ç»œæ˜¯æ·±åº¦å­¦ä¹ çš„åŸºç¡€ï¼Œå®ƒæ¨¡æ‹Ÿäº†äººè„‘ç¥ç»å…ƒçš„å·¥ä½œåŸç†ã€‚

### 2.2 å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰
å·ç§¯ç¥ç»ç½‘ç»œæ˜¯ä¸“é—¨ç”¨äºå¤„ç†å…·æœ‰ç½‘æ ¼ç»“æ„æ•°æ®ï¼ˆå¦‚å›¾åƒï¼‰çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚
"""
    
    print(f"ğŸ“„ åŸå§‹æ–‡æœ¬é•¿åº¦: {len(test_text)} å­—ç¬¦")
    print(f"ğŸ“„ åŸå§‹æ–‡æœ¬å†…å®¹é¢„è§ˆ:")
    print(test_text[:200] + "...")
    
    # æµ‹è¯•é¢„å¤„ç†
    print("\nğŸ”§ æµ‹è¯•æ–‡æœ¬é¢„å¤„ç†...")
    preprocess_config = PreprocessConfig()
    preprocessor = TextPreprocessor(preprocess_config)
    
    preprocessed_text = preprocessor.process(test_text)
    print(f"ğŸ“„ é¢„å¤„ç†åæ–‡æœ¬é•¿åº¦: {len(preprocessed_text)} å­—ç¬¦")
    print(f"ğŸ“„ é¢„å¤„ç†åæ–‡æœ¬å†…å®¹é¢„è§ˆ:")
    print(preprocessed_text[:200] + "...")
    
    if not preprocessed_text.strip():
        print("âŒ é¢„å¤„ç†åæ–‡æœ¬ä¸ºç©ºï¼")
        return
    
    # æµ‹è¯•åˆ†å‰²
    print("\nâœ‚ï¸ æµ‹è¯•æ–‡æœ¬åˆ†å‰²...")
    split_config = SplitConfig(
        chunk_size=400,
        chunk_overlap=50,
        min_chunk_size=100
    )
    
    splitter = RecursiveTextSplitter(split_config)
    
    try:
        import uuid
        test_doc_id = str(uuid.uuid4())
        chunks = splitter.split(preprocessed_text, test_doc_id)
        print(f"âœ… åˆ†å‰²æˆåŠŸ: ç”Ÿæˆ {len(chunks)} ä¸ªæ–‡æœ¬å—")
        
        for i, chunk in enumerate(chunks):
            print(f"ğŸ“ å— {i+1}: é•¿åº¦={len(chunk.content)}, å†…å®¹é¢„è§ˆ: {chunk.content[:100]}...")
            
    except Exception as e:
        print(f"âŒ åˆ†å‰²å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_text_splitting()