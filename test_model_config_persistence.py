#!/usr/bin/env python3
"""
æ¨¡å‹é…ç½®æŒä¹…åŒ–æµ‹è¯•

æµ‹è¯•æ·»åŠ æ¨¡å‹åé…ç½®æ˜¯å¦æ­£ç¡®ä¿å­˜åˆ°é…ç½®æ–‡ä»¶
"""

import asyncio
import sys
import json
import yaml
from pathlib import Path
import aiohttp
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))


def print_section(title: str):
    """æ‰“å°æ ¼å¼åŒ–çš„ç« èŠ‚"""
    print(f"\n{'='*60}")
    print(f"ğŸ” {title}")
    print(f"{'='*60}")


def read_config_file():
    """è¯»å–é…ç½®æ–‡ä»¶"""
    config_path = Path("config/development.yaml")
    if config_path.exists():
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    return None


async def test_add_embedding_model_with_persistence():
    """æµ‹è¯•æ·»åŠ åµŒå…¥æ¨¡å‹å¹¶éªŒè¯é…ç½®æŒä¹…åŒ–"""
    print_section("æµ‹è¯•æ·»åŠ åµŒå…¥æ¨¡å‹å¹¶éªŒè¯é…ç½®æŒä¹…åŒ–")
    
    base_url = "http://localhost:8000"
    
    # 1. è¯»å–å½“å‰é…ç½®
    print("1. è¯»å–å½“å‰é…ç½®æ–‡ä»¶")
    original_config = read_config_file()
    if original_config:
        original_dimensions = original_config.get('embeddings', {}).get('dimensions', 'unknown')
        print(f"   ğŸ“‹ å½“å‰ç»´åº¦: {original_dimensions}")
    else:
        print("   âŒ æ— æ³•è¯»å–é…ç½®æ–‡ä»¶")
        return False
    
    # 2. æ„é€ æµ‹è¯•æ•°æ®
    print("\n2. æ„é€ æµ‹è¯•æ•°æ®")
    test_dimensions = 2048  # æ–°çš„ç»´åº¦å€¼
    model_data = {
        "model_type": "embedding",
        "name": "test_embedding_persistence",
        "provider": "siliconflow",
        "model_name": "BAAI/bge-large-zh-v1.5",
        "config": {
            "provider": "siliconflow",  # æ·»åŠ åˆ°configä¸­
            "dimensions": test_dimensions,  # å…³é”®ï¼šç”¨æˆ·è®¾ç½®çš„ç»´åº¦
            "batch_size": 50,
            "chunk_size": 1000,
            "chunk_overlap": 50,
            "timeout": 120,
            "api_key": "sk-test-persistence-key",
            "base_url": "https://api.siliconflow.cn/v1"
        }
    }
    
    print(f"   ğŸ“¤ æµ‹è¯•ç»´åº¦: {test_dimensions}")
    print(f"   ğŸ“¤ æ¨¡å‹åç§°: {model_data['model_name']}")
    
    # 3. å‘é€æ·»åŠ æ¨¡å‹è¯·æ±‚
    print("\n3. å‘é€æ·»åŠ æ¨¡å‹è¯·æ±‚")
    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(
                f"{base_url}/models/add",
                json=model_data,
                headers={"Content-Type": "application/json"}
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    print(f"   âœ… æ·»åŠ æ¨¡å‹æˆåŠŸ")
                    print(f"   ğŸ“‹ å“åº”: {result.get('message', 'No message')}")
                else:
                    error_text = await response.text()
                    print(f"   âŒ æ·»åŠ æ¨¡å‹å¤±è´¥ (çŠ¶æ€ç : {response.status})")
                    print(f"   ğŸ“‹ é”™è¯¯: {error_text}")
                    return False
                    
    except Exception as e:
        print(f"   âŒ è¯·æ±‚å¤±è´¥: {str(e)}")
        print(f"   ğŸ’¡ è¯·ç¡®ä¿åç«¯æœåŠ¡æ­£åœ¨è¿è¡Œ: python -m rag_system.api.main")
        return False
    
    # 4. ç­‰å¾…é…ç½®æ–‡ä»¶æ›´æ–°
    print("\n4. ç­‰å¾…é…ç½®æ–‡ä»¶æ›´æ–°")
    time.sleep(2)  # ç­‰å¾…æ–‡ä»¶å†™å…¥å®Œæˆ
    
    # 5. éªŒè¯é…ç½®æ–‡ä»¶æ˜¯å¦å·²æ›´æ–°
    print("\n5. éªŒè¯é…ç½®æ–‡ä»¶æ›´æ–°")
    updated_config = read_config_file()
    if updated_config:
        updated_dimensions = updated_config.get('embeddings', {}).get('dimensions', 'unknown')
        updated_model = updated_config.get('embeddings', {}).get('model', 'unknown')
        updated_provider = updated_config.get('embeddings', {}).get('provider', 'unknown')
        
        print(f"   ğŸ“‹ æ›´æ–°åç»´åº¦: {updated_dimensions}")
        print(f"   ğŸ“‹ æ›´æ–°åæ¨¡å‹: {updated_model}")
        print(f"   ğŸ“‹ æ›´æ–°åæä¾›å•†: {updated_provider}")
        
        # éªŒè¯å…³é”®å‚æ•°
        success = True
        if updated_dimensions == test_dimensions:
            print(f"   âœ… ç»´åº¦å‚æ•°å·²æ­£ç¡®ä¿å­˜: {updated_dimensions}")
        else:
            print(f"   âŒ ç»´åº¦å‚æ•°ä¿å­˜é”™è¯¯: æœŸæœ› {test_dimensions}, å®é™… {updated_dimensions}")
            success = False
        
        if updated_model == model_data['model_name']:
            print(f"   âœ… æ¨¡å‹åç§°å·²æ­£ç¡®ä¿å­˜: {updated_model}")
        else:
            print(f"   âŒ æ¨¡å‹åç§°ä¿å­˜é”™è¯¯: æœŸæœ› {model_data['model_name']}, å®é™… {updated_model}")
            success = False
        
        if updated_provider == model_data['config']['provider']:
            print(f"   âœ… æä¾›å•†å·²æ­£ç¡®ä¿å­˜: {updated_provider}")
        else:
            print(f"   âŒ æä¾›å•†ä¿å­˜é”™è¯¯: æœŸæœ› {model_data['config']['provider']}, å®é™… {updated_provider}")
            success = False
        
        return success
    else:
        print("   âŒ æ— æ³•è¯»å–æ›´æ–°åçš„é…ç½®æ–‡ä»¶")
        return False


async def test_add_reranking_model_with_persistence():
    """æµ‹è¯•æ·»åŠ é‡æ’åºæ¨¡å‹å¹¶éªŒè¯é…ç½®æŒä¹…åŒ–"""
    print_section("æµ‹è¯•æ·»åŠ é‡æ’åºæ¨¡å‹å¹¶éªŒè¯é…ç½®æŒä¹…åŒ–")
    
    base_url = "http://localhost:8000"
    
    # æ„é€ æµ‹è¯•æ•°æ®
    model_data = {
        "model_type": "reranking",
        "name": "test_reranking_persistence",
        "provider": "siliconflow",
        "model_name": "BAAI/bge-reranker-v2-m3",
        "config": {
            "provider": "siliconflow",
            "batch_size": 16,  # æµ‹è¯•å€¼
            "max_length": 256,  # æµ‹è¯•å€¼
            "timeout": 30,
            "api_key": "sk-test-reranking-key",
            "base_url": "https://api.siliconflow.cn/v1"
        }
    }
    
    print(f"   ğŸ“¤ æµ‹è¯•æ‰¹å¤„ç†å¤§å°: {model_data['config']['batch_size']}")
    print(f"   ğŸ“¤ æµ‹è¯•æœ€å¤§é•¿åº¦: {model_data['config']['max_length']}")
    
    # å‘é€è¯·æ±‚
    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(
                f"{base_url}/models/add",
                json=model_data,
                headers={"Content-Type": "application/json"}
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    print(f"   âœ… æ·»åŠ é‡æ’åºæ¨¡å‹æˆåŠŸ")
                    print(f"   ğŸ“‹ å“åº”: {result.get('message', 'No message')}")
                else:
                    error_text = await response.text()
                    print(f"   âŒ æ·»åŠ é‡æ’åºæ¨¡å‹å¤±è´¥ (çŠ¶æ€ç : {response.status})")
                    print(f"   ğŸ“‹ é”™è¯¯: {error_text}")
                    return False
                    
    except Exception as e:
        print(f"   âŒ è¯·æ±‚å¤±è´¥: {str(e)}")
        return False
    
    # ç­‰å¾…å¹¶éªŒè¯é…ç½®æ–‡ä»¶
    time.sleep(2)
    updated_config = read_config_file()
    if updated_config:
        reranking_config = updated_config.get('reranking', {})
        updated_batch_size = reranking_config.get('batch_size', 'unknown')
        updated_max_length = reranking_config.get('max_length', 'unknown')
        updated_model = reranking_config.get('model', 'unknown')
        
        print(f"   ğŸ“‹ æ›´æ–°åæ‰¹å¤„ç†å¤§å°: {updated_batch_size}")
        print(f"   ğŸ“‹ æ›´æ–°åæœ€å¤§é•¿åº¦: {updated_max_length}")
        print(f"   ğŸ“‹ æ›´æ–°åæ¨¡å‹: {updated_model}")
        
        # éªŒè¯å‚æ•°
        success = True
        if updated_batch_size == model_data['config']['batch_size']:
            print(f"   âœ… æ‰¹å¤„ç†å¤§å°å·²æ­£ç¡®ä¿å­˜")
        else:
            print(f"   âŒ æ‰¹å¤„ç†å¤§å°ä¿å­˜é”™è¯¯")
            success = False
        
        if updated_max_length == model_data['config']['max_length']:
            print(f"   âœ… æœ€å¤§é•¿åº¦å·²æ­£ç¡®ä¿å­˜")
        else:
            print(f"   âŒ æœ€å¤§é•¿åº¦ä¿å­˜é”™è¯¯")
            success = False
        
        return success
    else:
        print("   âŒ æ— æ³•è¯»å–æ›´æ–°åçš„é…ç½®æ–‡ä»¶")
        return False


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æ¨¡å‹é…ç½®æŒä¹…åŒ–æµ‹è¯•")
    print("æµ‹è¯•æ·»åŠ æ¨¡å‹åé…ç½®æ˜¯å¦æ­£ç¡®ä¿å­˜åˆ°é…ç½®æ–‡ä»¶")
    
    results = []
    
    try:
        # 1. æµ‹è¯•åµŒå…¥æ¨¡å‹é…ç½®æŒä¹…åŒ–
        results.append(await test_add_embedding_model_with_persistence())
        
        # 2. æµ‹è¯•é‡æ’åºæ¨¡å‹é…ç½®æŒä¹…åŒ–
        results.append(await test_add_reranking_model_with_persistence())
        
        print_section("æµ‹è¯•æ€»ç»“")
        
        test_names = ["åµŒå…¥æ¨¡å‹é…ç½®æŒä¹…åŒ–", "é‡æ’åºæ¨¡å‹é…ç½®æŒä¹…åŒ–"]
        
        print("ğŸ“Š æµ‹è¯•ç»“æœ:")
        for i, (name, result) in enumerate(zip(test_names, results), 1):
            status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
            print(f"   {i}. {name}: {status}")
        
        if all(results):
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
            print("ğŸ¯ æ¨¡å‹é…ç½®æŒä¹…åŒ–åŠŸèƒ½æ­£å¸¸å·¥ä½œ:")
            print("   âœ… æ·»åŠ åµŒå…¥æ¨¡å‹æ—¶ï¼Œç»´åº¦å‚æ•°æ­£ç¡®ä¿å­˜åˆ°é…ç½®æ–‡ä»¶")
            print("   âœ… æ·»åŠ é‡æ’åºæ¨¡å‹æ—¶ï¼Œå‚æ•°æ­£ç¡®ä¿å­˜åˆ°é…ç½®æ–‡ä»¶")
            print("   âœ… ç”¨æˆ·ä¿®æ”¹çš„å‚æ•°ä¸ä¼šä¸¢å¤±")
            print("   âœ… é…ç½®æ–‡ä»¶ä¸å†…å­˜çŠ¶æ€ä¿æŒåŒæ­¥")
            
            print("\nğŸ’¡ ç”¨æˆ·ç°åœ¨å¯ä»¥:")
            print("   1. åœ¨å‰ç«¯ä¿®æ”¹åµŒå…¥æ¨¡å‹ç»´åº¦å‚æ•°")
            print("   2. ç‚¹å‡»æ·»åŠ æ¨¡å‹æŒ‰é’®")
            print("   3. é…ç½®ä¼šåŒæ—¶ä¿å­˜åˆ°å†…å­˜å’Œé…ç½®æ–‡ä»¶")
            print("   4. é‡å¯æœåŠ¡åé…ç½®ä»ç„¶æœ‰æ•ˆ")
            
        else:
            failed_tests = [name for name, result in zip(test_names, results) if not result]
            print(f"\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥: {', '.join(failed_tests)}")
            
            print("\nğŸ”§ å¯èƒ½çš„é—®é¢˜:")
            print("   - åç«¯æœåŠ¡æœªè¿è¡Œ")
            print("   - é…ç½®æ–‡ä»¶å†™å…¥æƒé™é—®é¢˜")
            print("   - save_model_config_to_file å‡½æ•°å®ç°é—®é¢˜")
            print("   - é…ç½®æ–‡ä»¶è·¯å¾„é”™è¯¯")
        
        return all(results)
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)