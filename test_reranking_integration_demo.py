#!/usr/bin/env python3
"""
é‡æ’åºé›†æˆåŠŸèƒ½æ¼”ç¤ºè„šæœ¬

æ¼”ç¤ºé‡æ’åºåŠŸèƒ½ä¸æ£€ç´¢æµç¨‹çš„é›†æˆï¼š
- å¯¹æ¯”å¯ç”¨å’Œç¦ç”¨é‡æ’åºçš„æ£€ç´¢ç»“æœ
- å±•ç¤ºé‡æ’åºå¯¹ç»“æœæ’åºçš„å½±å“
- æ˜¾ç¤ºæ€§èƒ½ç›‘æ§å’Œç»Ÿè®¡ä¿¡æ¯
"""

import asyncio
import json
from datetime import datetime
from unittest.mock import AsyncMock, Mock

from rag_system.services.enhanced_retrieval_service import EnhancedRetrievalService
from rag_system.models.config import RetrievalConfig
from rag_system.models.vector import SearchResult


async def create_mock_enhanced_service():
    """åˆ›å»ºæ¨¡æ‹Ÿçš„å¢å¼ºæ£€ç´¢æœåŠ¡"""
    config = {
        'default_top_k': 5,
        'similarity_threshold': 0.7,
        'search_mode': 'semantic',
        'enable_rerank': True,
        'enable_cache': False,
        'model_name': 'cross-encoder/ms-marco-MiniLM-L-6-v2',
        'batch_size': 32,
        'timeout': 30.0
    }
    
    service = EnhancedRetrievalService(config)
    
    # åˆ›å»ºç¤ºä¾‹æ£€ç´¢ç»“æœ
    import uuid
    sample_results = [
        SearchResult(
            chunk_id=str(uuid.uuid4()),
            document_id=str(uuid.uuid4()),
            content=f"è¿™æ˜¯å…³äºäººå·¥æ™ºèƒ½çš„æ–‡æ¡£{i}ï¼ŒåŒ…å«æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ çš„å†…å®¹ã€‚",
            similarity_score=0.85 - i * 0.05,
            metadata={"source": f"ai_doc_{i}.txt", "topic": "AI", "length": 150 + i * 20}
        ) for i in range(5)
    ]
    
    # æ¨¡æ‹Ÿæœç´¢è·¯ç”±å™¨
    service.search_router.search_with_mode = AsyncMock(return_value=sample_results)
    service.search_router.get_usage_statistics = Mock(return_value={
        'semantic_searches': 2,
        'keyword_searches': 0,
        'hybrid_searches': 0,
        'total_searches': 2
    })
    
    # æ¨¡æ‹Ÿç¼“å­˜æœåŠ¡
    service.cache_service.get_cached_results = AsyncMock(return_value=None)
    service.cache_service.cache_results = AsyncMock()
    service.cache_service.get_cache_info = AsyncMock(return_value={
        'enabled': False,
        'hit_rate': 0.0
    })
    
    # æ¨¡æ‹Ÿé‡æ’åºæœåŠ¡
    async def mock_rerank(query, results, config):
        """æ¨¡æ‹Ÿé‡æ’åºé€»è¾‘"""
        if not config.enable_rerank:
            return results
        
        # æ¨¡æ‹Ÿé‡æ’åºï¼šæ ¹æ®æŸ¥è¯¢å†…å®¹è°ƒæ•´åˆ†æ•°
        reranked_results = []
        for i, result in enumerate(results):
            # æ¨¡æ‹Ÿäº¤å‰ç¼–ç å™¨ç»™å‡ºçš„æ–°åˆ†æ•°
            new_score = 0.95 - i * 0.08  # é‡æ’åºåçš„åˆ†æ•°
            
            reranked_result = SearchResult(
                chunk_id=result.chunk_id,
                document_id=result.document_id,
                content=result.content,
                similarity_score=new_score,
                metadata={
                    **result.metadata,
                    'original_score': result.similarity_score,
                    'rerank_score': new_score,
                    'rerank_rank': i + 1
                }
            )
            reranked_results.append(reranked_result)
        
        # æŒ‰æ–°åˆ†æ•°æ’åºï¼ˆè¿™é‡Œä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬åè½¬é¡ºåºï¼‰
        reranked_results.reverse()
        
        # æ›´æ–°æœ€ç»ˆæ’å
        for i, result in enumerate(reranked_results):
            result.metadata['final_rank'] = i + 1
        
        return reranked_results
    
    service.reranking_service.rerank_results = mock_rerank
    service.reranking_service.get_metrics = Mock(return_value={
        'model_loaded': True,
        'model_name': 'cross-encoder/ms-marco-MiniLM-L-6-v2',
        'total_requests': 1,
        'successful_requests': 1,
        'failed_requests': 0,
        'success_rate': 1.0,
        'average_processing_time': 0.125
    })
    
    return service


async def demonstrate_reranking_integration():
    """æ¼”ç¤ºé‡æ’åºé›†æˆåŠŸèƒ½"""
    print("ğŸš€ é‡æ’åºé›†æˆåŠŸèƒ½æ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºå¢å¼ºæ£€ç´¢æœåŠ¡
    service = await create_mock_enhanced_service()
    
    # æµ‹è¯•æŸ¥è¯¢
    test_query = "äººå·¥æ™ºèƒ½å’Œæœºå™¨å­¦ä¹ çš„æœ€æ–°å‘å±•"
    
    print(f"ğŸ“ æµ‹è¯•æŸ¥è¯¢: {test_query}")
    print()
    
    # 1. ä¸å¯ç”¨é‡æ’åºçš„æœç´¢
    print("1ï¸âƒ£ ä¸å¯ç”¨é‡æ’åºçš„æœç´¢ç»“æœ:")
    print("-" * 40)
    
    config_no_rerank = RetrievalConfig(
        search_mode='semantic',
        enable_rerank=False,
        enable_cache=False,
        top_k=5
    )
    
    start_time = datetime.now()
    results_no_rerank = await service.search_with_config(test_query, config_no_rerank)
    no_rerank_time = (datetime.now() - start_time).total_seconds()
    
    for i, result in enumerate(results_no_rerank):
        print(f"  {i+1}. åˆ†æ•°: {result.similarity_score:.3f} | {result.content[:50]}...")
    
    print(f"â±ï¸  æœç´¢è€—æ—¶: {no_rerank_time:.3f}ç§’")
    print()
    
    # 2. å¯ç”¨é‡æ’åºçš„æœç´¢
    print("2ï¸âƒ£ å¯ç”¨é‡æ’åºçš„æœç´¢ç»“æœ:")
    print("-" * 40)
    
    config_with_rerank = RetrievalConfig(
        search_mode='semantic',
        enable_rerank=True,
        enable_cache=False,
        top_k=5
    )
    
    start_time = datetime.now()
    results_with_rerank = await service.search_with_config(test_query, config_with_rerank)
    rerank_time = (datetime.now() - start_time).total_seconds()
    
    for i, result in enumerate(results_with_rerank):
        original_score = result.metadata.get('original_score', 'N/A')
        rerank_score = result.metadata.get('rerank_score', result.similarity_score)
        print(f"  {i+1}. é‡æ’åºåˆ†æ•°: {rerank_score:.3f} (åŸå§‹: {original_score}) | {result.content[:50]}...")
    
    print(f"â±ï¸  æœç´¢è€—æ—¶: {rerank_time:.3f}ç§’")
    print()
    
    # 3. å¯¹æ¯”åˆ†æ
    print("3ï¸âƒ£ å¯¹æ¯”åˆ†æ:")
    print("-" * 40)
    
    print(f"ğŸ“Š ç»“æœæ•°é‡å¯¹æ¯”:")
    print(f"   - æ— é‡æ’åº: {len(results_no_rerank)} ä¸ªç»“æœ")
    print(f"   - æœ‰é‡æ’åº: {len(results_with_rerank)} ä¸ªç»“æœ")
    print()
    
    print(f"â±ï¸  æ€§èƒ½å¯¹æ¯”:")
    print(f"   - æ— é‡æ’åºè€—æ—¶: {no_rerank_time:.3f}ç§’")
    print(f"   - æœ‰é‡æ’åºè€—æ—¶: {rerank_time:.3f}ç§’")
    print(f"   - é‡æ’åºå¼€é”€: {rerank_time - no_rerank_time:.3f}ç§’")
    print()
    
    print(f"ğŸ”„ æ’åºå˜åŒ–:")
    if len(results_no_rerank) == len(results_with_rerank):
        for i in range(len(results_no_rerank)):
            no_rerank_id = results_no_rerank[i].chunk_id
            rerank_id = results_with_rerank[i].chunk_id
            if no_rerank_id != rerank_id:
                print(f"   - ä½ç½® {i+1}: ç»“æœå‘ç”Ÿå˜åŒ–")
            else:
                print(f"   - ä½ç½® {i+1}: ç»“æœä¿æŒä¸å˜")
    print()
    
    # 4. è·å–ç»Ÿè®¡ä¿¡æ¯
    print("4ï¸âƒ£ æœåŠ¡ç»Ÿè®¡ä¿¡æ¯:")
    print("-" * 40)
    
    stats = service.get_search_statistics()
    
    print(f"ğŸ” æœç´¢ç»Ÿè®¡:")
    router_stats = stats.get('router_statistics', {})
    print(f"   - æ€»æœç´¢æ¬¡æ•°: {router_stats.get('total_searches', 0)}")
    print(f"   - è¯­ä¹‰æœç´¢: {router_stats.get('semantic_searches', 0)}")
    print()
    
    print(f"ğŸ”„ é‡æ’åºç»Ÿè®¡:")
    rerank_stats = stats.get('reranking_statistics', {})
    print(f"   - é‡æ’åºè¯·æ±‚: {rerank_stats.get('total_rerank_requests', 0)}")
    print(f"   - æˆåŠŸé‡æ’åº: {rerank_stats.get('successful_reranks', 0)}")
    print(f"   - å¤±è´¥é‡æ’åº: {rerank_stats.get('failed_reranks', 0)}")
    print(f"   - æˆåŠŸç‡: {rerank_stats.get('rerank_success_rate', 0):.1%}")
    print(f"   - å¹³å‡è€—æ—¶: {rerank_stats.get('avg_rerank_time', 0):.3f}ç§’")
    print()
    
    # 5. é‡æ’åºæœåŠ¡æŒ‡æ ‡
    print("5ï¸âƒ£ é‡æ’åºæœåŠ¡æŒ‡æ ‡:")
    print("-" * 40)
    
    rerank_metrics = await service.get_reranking_metrics()
    print(f"ğŸ¤– æ¨¡å‹çŠ¶æ€:")
    print(f"   - æ¨¡å‹å·²åŠ è½½: {rerank_metrics.get('model_loaded', False)}")
    print(f"   - æ¨¡å‹åç§°: {rerank_metrics.get('model_name', 'N/A')}")
    print()
    
    print(f"ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡:")
    print(f"   - æ€»è¯·æ±‚æ•°: {rerank_metrics.get('total_requests', 0)}")
    print(f"   - æˆåŠŸè¯·æ±‚: {rerank_metrics.get('successful_requests', 0)}")
    print(f"   - å¤±è´¥è¯·æ±‚: {rerank_metrics.get('failed_requests', 0)}")
    print(f"   - æˆåŠŸç‡: {rerank_metrics.get('success_rate', 0):.1%}")
    print(f"   - å¹³å‡å¤„ç†æ—¶é—´: {rerank_metrics.get('average_processing_time', 0):.3f}ç§’")
    print()
    
    # 6. å¥åº·æ£€æŸ¥
    print("6ï¸âƒ£ ç³»ç»Ÿå¥åº·æ£€æŸ¥:")
    print("-" * 40)
    
    health = await service.health_check()
    print(f"ğŸ¥ æ•´ä½“çŠ¶æ€: {health.get('status', 'unknown')}")
    
    components = health.get('components', {})
    for component_name, component_health in components.items():
        if isinstance(component_health, dict):
            status = component_health.get('status', 'unknown')
        else:
            status = component_health
        print(f"   - {component_name}: {status}")
    print()
    
    print("âœ… é‡æ’åºé›†æˆåŠŸèƒ½æ¼”ç¤ºå®Œæˆï¼")
    print("=" * 60)


async def main():
    """ä¸»å‡½æ•°"""
    try:
        await demonstrate_reranking_integration()
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())