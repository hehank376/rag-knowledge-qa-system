#!/usr/bin/env python3
"""
é…ç½®ä¿å­˜åŠŸèƒ½æµ‹è¯•è„šæœ¬

æµ‹è¯•æ¨¡å‹é…ç½®çš„ä¿å­˜å’ŒåŠ è½½åŠŸèƒ½ï¼š
- é…ç½®æ–‡ä»¶ä¿å­˜
- å‚æ•°ä¿®æ”¹æŒä¹…åŒ–
- é…ç½®é‡æ–°åŠ è½½
- å‰åç«¯é…ç½®åŒæ­¥
"""

import asyncio
import json
import yaml
import tempfile
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, Any

from fastapi import FastAPI
from fastapi.testclient import TestClient

# å¯¼å…¥æˆ‘ä»¬çš„API
from rag_system.api.config_api import router as config_router


def print_section(title: str, content: str = ""):
    """æ‰“å°æ ¼å¼åŒ–çš„ç« èŠ‚"""
    print(f"\n{'='*60}")
    print(f"ğŸ§ª {title}")
    print(f"{'='*60}")
    if content:
        print(content)


def print_test_result(test_name: str, success: bool, details: str = ""):
    """æ‰“å°æµ‹è¯•ç»“æœ"""
    status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
    print(f"{status} {test_name}")
    if details:
        print(f"   è¯¦æƒ…: {details}")


def create_test_app():
    """åˆ›å»ºæµ‹è¯•åº”ç”¨"""
    app = FastAPI(title="é…ç½®ä¿å­˜åŠŸèƒ½æµ‹è¯•")
    app.include_router(config_router)
    return app


def create_test_config_file():
    """åˆ›å»ºæµ‹è¯•é…ç½®æ–‡ä»¶"""
    test_config = {
        "app": {
            "name": "RAG Test System",
            "version": "1.0.0-test",
            "debug": True
        },
        "embeddings": {
            "provider": "mock",
            "model": "test-embedding-model",
            "api_key": "test_key",
            "base_url": "https://api.test.com/v1",
            "chunk_size": 1000,
            "chunk_overlap": 200,
            "batch_size": 100,
            "timeout": 60
        },
        "reranking": {
            "provider": "sentence_transformers",
            "model": "cross-encoder/ms-marco-MiniLM-L-6-v2",
            "batch_size": 32,
            "max_length": 512,
            "timeout": 30.0
        },
        "llm": {
            "provider": "mock",
            "model": "test-llm-model",
            "api_key": "test_llm_key",
            "temperature": 0.7,
            "max_tokens": 1000
        },
        "retrieval": {
            "top_k": 5,
            "similarity_threshold": 0.7,
            "search_mode": "hybrid",
            "enable_rerank": True,
            "enable_cache": True
        }
    }
    
    # åˆ›å»ºä¸´æ—¶é…ç½®æ–‡ä»¶
    temp_file = tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False)
    yaml.dump(test_config, temp_file, default_flow_style=False, allow_unicode=True, indent=2)
    temp_file.close()
    
    return temp_file.name, test_config


async def test_embedding_config_save():
    """æµ‹è¯•åµŒå…¥æ¨¡å‹é…ç½®ä¿å­˜"""
    print_section("æµ‹è¯•åµŒå…¥æ¨¡å‹é…ç½®ä¿å­˜")
    
    app = create_test_app()
    client = TestClient(app)
    
    try:
        # æµ‹è¯•æ·»åŠ åµŒå…¥æ¨¡å‹é…ç½®
        model_data = {
            "model_type": "embedding",
            "name": "test_siliconflow_embedding",
            "provider": "siliconflow",
            "model_name": "BAAI/bge-large-zh-v1.5",
            "config": {
                "api_key": "sk-test123456789",
                "base_url": "https://api.siliconflow.cn/v1",
                "chunk_size": 800,
                "chunk_overlap": 100,
                "batch_size": 64,
                "timeout": 120
            },
            "enabled": True,
            "priority": 8
        }
        
        response = client.post("/config/models/add-model", json=model_data)
        
        if response.status_code == 200:
            data = response.json()
            success = data.get("success", False)
            print_test_result("æ·»åŠ åµŒå…¥æ¨¡å‹é…ç½®", success, 
                            f"å“åº”: {data.get('message', 'æ— æ¶ˆæ¯')}")
            
            # éªŒè¯é…ç½®æ˜¯å¦ä¿å­˜åˆ°æ–‡ä»¶
            if success:
                # æ£€æŸ¥é…ç½®æ˜¯å¦æ­£ç¡®åŠ è½½
                config_response = client.get("/config/embeddings")
                if config_response.status_code == 200:
                    config_data = config_response.json()
                    if config_data.get("success"):
                        embedding_config = config_data.get("config", {}).get("embeddings", {})
                        expected_values = {
                            "provider": "siliconflow",
                            "model": "BAAI/bge-large-zh-v1.5",
                            "chunk_size": 800,
                            "chunk_overlap": 100,
                            "batch_size": 64
                        }
                        
                        all_match = True
                        for key, expected_value in expected_values.items():
                            actual_value = embedding_config.get(key)
                            if actual_value != expected_value:
                                print(f"   é…ç½®ä¸åŒ¹é…: {key} = {actual_value}, æœŸæœ›: {expected_value}")
                                all_match = False
                        
                        print_test_result("é…ç½®ä¿å­˜éªŒè¯", all_match, 
                                        f"é…ç½®å†…å®¹: {json.dumps(embedding_config, indent=2, ensure_ascii=False)}")
                        return all_match
            
            return success
        else:
            print_test_result("æ·»åŠ åµŒå…¥æ¨¡å‹é…ç½®", False, f"HTTPçŠ¶æ€ç : {response.status_code}")
            return False
            
    except Exception as e:
        print_test_result("æ·»åŠ åµŒå…¥æ¨¡å‹é…ç½®", False, f"å¼‚å¸¸: {str(e)}")
        return False


async def test_reranking_config_save():
    """æµ‹è¯•é‡æ’åºæ¨¡å‹é…ç½®ä¿å­˜"""
    print_section("æµ‹è¯•é‡æ’åºæ¨¡å‹é…ç½®ä¿å­˜")
    
    app = create_test_app()
    client = TestClient(app)
    
    try:
        # æµ‹è¯•æ·»åŠ é‡æ’åºæ¨¡å‹é…ç½®
        model_data = {
            "model_type": "reranking",
            "name": "test_reranking_model",
            "provider": "sentence_transformers",
            "model_name": "cross-encoder/ms-marco-MiniLM-L-12-v2",
            "config": {
                "batch_size": 16,
                "max_length": 256,
                "timeout": 45.0
            },
            "enabled": True,
            "priority": 7
        }
        
        response = client.post("/config/models/add-model", json=model_data)
        
        if response.status_code == 200:
            data = response.json()
            success = data.get("success", False)
            print_test_result("æ·»åŠ é‡æ’åºæ¨¡å‹é…ç½®", success, 
                            f"å“åº”: {data.get('message', 'æ— æ¶ˆæ¯')}")
            return success
        else:
            print_test_result("æ·»åŠ é‡æ’åºæ¨¡å‹é…ç½®", False, f"HTTPçŠ¶æ€ç : {response.status_code}")
            return False
            
    except Exception as e:
        print_test_result("æ·»åŠ é‡æ’åºæ¨¡å‹é…ç½®", False, f"å¼‚å¸¸: {str(e)}")
        return False


async def test_model_switch_save():
    """æµ‹è¯•æ¨¡å‹åˆ‡æ¢é…ç½®ä¿å­˜"""
    print_section("æµ‹è¯•æ¨¡å‹åˆ‡æ¢é…ç½®ä¿å­˜")
    
    app = create_test_app()
    client = TestClient(app)
    
    try:
        # å…ˆæ·»åŠ ä¸€ä¸ªæ¨¡å‹
        model_data = {
            "model_type": "embedding",
            "name": "test_openai_embedding",
            "provider": "openai",
            "model_name": "text-embedding-ada-002",
            "config": {
                "api_key": "sk-openai123456789",
                "base_url": "https://api.openai.com/v1",
                "chunk_size": 1200,
                "chunk_overlap": 150,
                "batch_size": 50
            },
            "enabled": True,
            "priority": 9
        }
        
        add_response = client.post("/config/models/add-model", json=model_data)
        
        if add_response.status_code == 200 and add_response.json().get("success"):
            # æµ‹è¯•åˆ‡æ¢åˆ°è¿™ä¸ªæ¨¡å‹
            switch_data = {
                "model_type": "embedding",
                "model_name": "text-embedding-ada-002"
            }
            
            switch_response = client.post("/config/models/switch-active", json=switch_data)
            
            if switch_response.status_code == 200:
                switch_result = switch_response.json()
                success = switch_result.get("success", False)
                print_test_result("åˆ‡æ¢åµŒå…¥æ¨¡å‹", success, 
                                f"å“åº”: {switch_result.get('message', 'æ— æ¶ˆæ¯')}")
                
                # éªŒè¯åˆ‡æ¢åçš„é…ç½®
                if success:
                    config_response = client.get("/config/embeddings")
                    if config_response.status_code == 200:
                        config_data = config_response.json()
                        if config_data.get("success"):
                            embedding_config = config_data.get("config", {}).get("embeddings", {})
                            current_model = embedding_config.get("model")
                            print_test_result("æ¨¡å‹åˆ‡æ¢éªŒè¯", current_model == "text-embedding-ada-002",
                                            f"å½“å‰æ¨¡å‹: {current_model}")
                            return current_model == "text-embedding-ada-002"
                
                return success
            else:
                print_test_result("åˆ‡æ¢åµŒå…¥æ¨¡å‹", False, f"HTTPçŠ¶æ€ç : {switch_response.status_code}")
                return False
        else:
            print_test_result("æ·»åŠ æµ‹è¯•æ¨¡å‹", False, "æ·»åŠ æ¨¡å‹å¤±è´¥ï¼Œæ— æ³•æµ‹è¯•åˆ‡æ¢")
            return False
            
    except Exception as e:
        print_test_result("æµ‹è¯•æ¨¡å‹åˆ‡æ¢", False, f"å¼‚å¸¸: {str(e)}")
        return False


async def test_config_update_api():
    """æµ‹è¯•é…ç½®æ›´æ–°API"""
    print_section("æµ‹è¯•é…ç½®æ›´æ–°API")
    
    app = create_test_app()
    client = TestClient(app)
    
    try:
        # æµ‹è¯•æ›´æ–°æ¨¡å‹é…ç½®
        update_data = {
            "embeddings": {
                "provider": "huggingface",
                "model": "sentence-transformers/all-mpnet-base-v2",
                "api_key": "hf_test123456789",
                "base_url": "https://api-inference.huggingface.co",
                "chunk_size": 600,
                "chunk_overlap": 80,
                "batch_size": 32,
                "timeout": 90
            },
            "reranking": {
                "provider": "huggingface",
                "model": "cross-encoder/ms-marco-TinyBERT-L-2-v2",
                "batch_size": 64,
                "max_length": 128,
                "timeout": 20.0
            }
        }
        
        response = client.post("/config/models/update-config", json=update_data)
        
        if response.status_code == 200:
            data = response.json()
            success = data.get("success", False)
            print_test_result("æ›´æ–°æ¨¡å‹é…ç½®", success, 
                            f"å“åº”: {data.get('message', 'æ— æ¶ˆæ¯')}")
            
            # éªŒè¯æ›´æ–°åçš„é…ç½®
            if success:
                config_response = client.get("/config/embeddings")
                if config_response.status_code == 200:
                    config_data = config_response.json()
                    if config_data.get("success"):
                        embedding_config = config_data.get("config", {}).get("embeddings", {})
                        expected_provider = "huggingface"
                        expected_model = "sentence-transformers/all-mpnet-base-v2"
                        expected_chunk_size = 600
                        
                        provider_match = embedding_config.get("provider") == expected_provider
                        model_match = embedding_config.get("model") == expected_model
                        chunk_size_match = embedding_config.get("chunk_size") == expected_chunk_size
                        
                        all_match = provider_match and model_match and chunk_size_match
                        print_test_result("é…ç½®æ›´æ–°éªŒè¯", all_match,
                                        f"Provider: {embedding_config.get('provider')}, "
                                        f"Model: {embedding_config.get('model')}, "
                                        f"Chunk Size: {embedding_config.get('chunk_size')}")
                        return all_match
            
            return success
        else:
            print_test_result("æ›´æ–°æ¨¡å‹é…ç½®", False, f"HTTPçŠ¶æ€ç : {response.status_code}")
            return False
            
    except Exception as e:
        print_test_result("æµ‹è¯•é…ç½®æ›´æ–°", False, f"å¼‚å¸¸: {str(e)}")
        return False


async def test_config_persistence():
    """æµ‹è¯•é…ç½®æŒä¹…åŒ–"""
    print_section("æµ‹è¯•é…ç½®æŒä¹…åŒ–")
    
    try:
        # åˆ›å»ºæµ‹è¯•é…ç½®æ–‡ä»¶
        config_file, original_config = create_test_config_file()
        
        print_test_result("åˆ›å»ºæµ‹è¯•é…ç½®æ–‡ä»¶", True, f"æ–‡ä»¶è·¯å¾„: {config_file}")
        
        # æ¨¡æ‹Ÿé…ç½®ä¿®æ”¹
        modified_config = original_config.copy()
        modified_config["embeddings"]["model"] = "new-test-model"
        modified_config["embeddings"]["chunk_size"] = 1500
        modified_config["reranking"]["batch_size"] = 64
        
        # ä¿å­˜ä¿®æ”¹åçš„é…ç½®
        with open(config_file, 'w', encoding='utf-8') as f:
            yaml.dump(modified_config, f, default_flow_style=False, allow_unicode=True, indent=2)
        
        print_test_result("ä¿å­˜ä¿®æ”¹åçš„é…ç½®", True, "é…ç½®å·²å†™å…¥æ–‡ä»¶")
        
        # é‡æ–°è¯»å–é…ç½®éªŒè¯
        with open(config_file, 'r', encoding='utf-8') as f:
            loaded_config = yaml.safe_load(f)
        
        # éªŒè¯ä¿®æ”¹æ˜¯å¦æŒä¹…åŒ–
        embedding_model_match = loaded_config["embeddings"]["model"] == "new-test-model"
        chunk_size_match = loaded_config["embeddings"]["chunk_size"] == 1500
        reranking_batch_match = loaded_config["reranking"]["batch_size"] == 64
        
        all_match = embedding_model_match and chunk_size_match and reranking_batch_match
        print_test_result("é…ç½®æŒä¹…åŒ–éªŒè¯", all_match,
                        f"Embedding Model: {loaded_config['embeddings']['model']}, "
                        f"Chunk Size: {loaded_config['embeddings']['chunk_size']}, "
                        f"Reranking Batch: {loaded_config['reranking']['batch_size']}")
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        os.unlink(config_file)
        print_test_result("æ¸…ç†æµ‹è¯•æ–‡ä»¶", True, "æµ‹è¯•æ–‡ä»¶å·²åˆ é™¤")
        
        return all_match
        
    except Exception as e:
        print_test_result("æµ‹è¯•é…ç½®æŒä¹…åŒ–", False, f"å¼‚å¸¸: {str(e)}")
        return False


async def run_comprehensive_test():
    """è¿è¡Œç»¼åˆæµ‹è¯•"""
    print("ğŸš€ é…ç½®ä¿å­˜åŠŸèƒ½ç»¼åˆæµ‹è¯•")
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    test_results = []
    
    # è¿è¡Œå„é¡¹æµ‹è¯•
    test_functions = [
        ("åµŒå…¥æ¨¡å‹é…ç½®ä¿å­˜", test_embedding_config_save),
        ("é‡æ’åºæ¨¡å‹é…ç½®ä¿å­˜", test_reranking_config_save),
        ("æ¨¡å‹åˆ‡æ¢é…ç½®ä¿å­˜", test_model_switch_save),
        ("é…ç½®æ›´æ–°API", test_config_update_api),
        ("é…ç½®æŒä¹…åŒ–", test_config_persistence)
    ]
    
    for test_name, test_func in test_functions:
        try:
            result = await test_func()
            test_results.append((test_name, result))
        except Exception as e:
            print_test_result(test_name, False, f"æµ‹è¯•å¼‚å¸¸: {str(e)}")
            test_results.append((test_name, False))
    
    # æµ‹è¯•æ€»ç»“
    print_section("æµ‹è¯•æ€»ç»“")
    
    passed_tests = sum(1 for _, result in test_results if result)
    total_tests = len(test_results)
    
    print(f"æ€»æµ‹è¯•æ•°: {total_tests}")
    print(f"é€šè¿‡æµ‹è¯•: {passed_tests}")
    print(f"å¤±è´¥æµ‹è¯•: {total_tests - passed_tests}")
    print(f"é€šè¿‡ç‡: {passed_tests/total_tests*100:.1f}%")
    
    print("\nè¯¦ç»†ç»“æœ:")
    for test_name, result in test_results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"  {status} {test_name}")
    
    # åŠŸèƒ½ç‰¹æ€§æ€»ç»“
    print_section("é…ç½®ä¿å­˜åŠŸèƒ½ç‰¹æ€§")
    
    features = [
        "âœ… åµŒå…¥æ¨¡å‹é…ç½®ä¿å­˜åˆ°YAMLæ–‡ä»¶",
        "âœ… é‡æ’åºæ¨¡å‹é…ç½®ä¿å­˜åˆ°YAMLæ–‡ä»¶", 
        "âœ… æ¨¡å‹åˆ‡æ¢æ—¶é…ç½®è‡ªåŠ¨æ›´æ–°",
        "âœ… é…ç½®å‚æ•°ä¿®æ”¹æŒä¹…åŒ–",
        "âœ… é…ç½®é‡æ–°åŠ è½½æœºåˆ¶",
        "âœ… APIå¯†é’¥å’ŒåŸºç¡€URLä¿å­˜",
        "âœ… æ‰¹å¤„ç†å¤§å°å’Œè¶…æ—¶å‚æ•°ä¿å­˜",
        "âœ… é…ç½®éªŒè¯å’Œé”™è¯¯å¤„ç†"
    ]
    
    for feature in features:
        print(f"  {feature}")
    
    return passed_tests == total_tests


if __name__ == "__main__":
    asyncio.run(run_comprehensive_test())