#!/usr/bin/env python3
"""
æµ‹è¯•çœŸå®æ¨¡å‹è¿æ¥
"""
import requests
import json
import os
import sys

def test_real_connections():
    base_url = "http://localhost:8000"
    
    print("ğŸ§ª æµ‹è¯•çœŸå®æ¨¡å‹è¿æ¥...")
    print("âš ï¸  è¯·ç¡®ä¿å·²è®¾ç½®ç›¸åº”çš„APIå¯†é’¥ç¯å¢ƒå˜é‡")
    print("OPENAI_API_KEYå­˜åœ¨å—:", "OPENAI_API_KEY" in os.environ)
    print("SILICONFLOW_API_KEYå­˜åœ¨å—:", "SILICONFLOWFLOW_API_KEY" in os.environ)
    # è·å–APIå¯†é’¥
    openai_key = os.getenv("OPENAI_API_KEY")
    siliconflow_key = os.getenv("SILICONFLOW_API_KEY")
    
    #print('==========' siliconflow_key)
    
    if not openai_key and not siliconflow_key:
        print("âŒ æœªæ‰¾åˆ°APIå¯†é’¥ç¯å¢ƒå˜é‡")
        print("è¯·è®¾ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡ä¹‹ä¸€:")
        print("  - OPENAI_API_KEY")
        print("  - SILICONFLOW_API_KEY")
        return
    
    # æµ‹è¯•SiliconFlow LLMè¿æ¥
    if siliconflow_key:
        print("\n1. æµ‹è¯•SiliconFlow LLMè¿æ¥...")
        try:
            llm_config = {
                "provider": "siliconflow",
                "model": "Qwen/Qwen2-7B-Instruct",
                "api_key": siliconflow_key,
                "temperature": 0.7,
                "max_tokens": 1000
            }
            response = requests.post(f"{base_url}/config/test/llm", json=llm_config)
            print(f"çŠ¶æ€ç : {response.status_code}")
            if response.status_code == 200:
                result = response.json()
                if result.get("success"):
                    print("âœ“ SiliconFlow LLMè¿æ¥æµ‹è¯•æˆåŠŸ")
                else:
                    print("âœ— SiliconFlow LLMè¿æ¥æµ‹è¯•å¤±è´¥")
                print(f"æµ‹è¯•ç»“æœ: {json.dumps(result, indent=2, ensure_ascii=False)}")
            else:
                print(f"âœ— SiliconFlow LLMè¿æ¥æµ‹è¯•å¤±è´¥: {response.text}")
        except Exception as e:
            print(f"âœ— SiliconFlow LLMè¿æ¥æµ‹è¯•å¼‚å¸¸: {e}")
    
    # æµ‹è¯•SiliconFlowåµŒå…¥æ¨¡å‹è¿æ¥
    if siliconflow_key:
        print("\n2. æµ‹è¯•SiliconFlowåµŒå…¥æ¨¡å‹è¿æ¥...")
        try:
            embedding_config = {
                "provider": "siliconflow",
                "model": "BAAI/bge-large-zh-v1.5",
                "api_key": siliconflow_key,
                "chunk_size": 1000,
                "chunk_overlap": 200
            }
            response = requests.post(f"{base_url}/config/test/embedding", json=embedding_config)
            print(f"çŠ¶æ€ç : {response.status_code}")
            if response.status_code == 200:
                result = response.json()
                if result.get("success"):
                    print("âœ“ SiliconFlowåµŒå…¥æ¨¡å‹è¿æ¥æµ‹è¯•æˆåŠŸ")
                else:
                    print("âœ— SiliconFlowåµŒå…¥æ¨¡å‹è¿æ¥æµ‹è¯•å¤±è´¥")
                print(f"æµ‹è¯•ç»“æœ: {json.dumps(result, indent=2, ensure_ascii=False)}")
            else:
                print(f"âœ— SiliconFlowåµŒå…¥æ¨¡å‹è¿æ¥æµ‹è¯•å¤±è´¥: {response.text}")
        except Exception as e:
            print(f"âœ— SiliconFlowåµŒå…¥æ¨¡å‹è¿æ¥æµ‹è¯•å¼‚å¸¸: {e}")
    
    # æµ‹è¯•OpenAI LLMè¿æ¥
    if openai_key:
        print("\n3. æµ‹è¯•OpenAI LLMè¿æ¥...")
        try:
            llm_config = {
                "provider": "openai",
                "model": "gpt-3.5-turbo",
                "api_key": openai_key,
                "temperature": 0.7,
                "max_tokens": 1000
            }
            response = requests.post(f"{base_url}/config/test/llm", json=llm_config)
            print(f"çŠ¶æ€ç : {response.status_code}")
            if response.status_code == 200:
                result = response.json()
                if result.get("success"):
                    print("âœ“ OpenAI LLMè¿æ¥æµ‹è¯•æˆåŠŸ")
                else:
                    print("âœ— OpenAI LLMè¿æ¥æµ‹è¯•å¤±è´¥")
                print(f"æµ‹è¯•ç»“æœ: {json.dumps(result, indent=2, ensure_ascii=False)}")
            else:
                print(f"âœ— OpenAI LLMè¿æ¥æµ‹è¯•å¤±è´¥: {response.text}")
        except Exception as e:
            print(f"âœ— OpenAI LLMè¿æ¥æµ‹è¯•å¼‚å¸¸: {e}")
    
    # æµ‹è¯•OpenAIåµŒå…¥æ¨¡å‹è¿æ¥
    if openai_key:
        print("\n4. æµ‹è¯•OpenAIåµŒå…¥æ¨¡å‹è¿æ¥...")
        try:
            embedding_config = {
                "provider": "openai",
                "model": "text-embedding-ada-002",
                "api_key": openai_key,
                "chunk_size": 1000,
                "chunk_overlap": 200
            }
            response = requests.post(f"{base_url}/config/test/embedding", json=embedding_config)
            print(f"çŠ¶æ€ç : {response.status_code}")
            if response.status_code == 200:
                result = response.json()
                if result.get("success"):
                    print("âœ“ OpenAIåµŒå…¥æ¨¡å‹è¿æ¥æµ‹è¯•æˆåŠŸ")
                else:
                    print("âœ— OpenAIåµŒå…¥æ¨¡å‹è¿æ¥æµ‹è¯•å¤±è´¥")
                print(f"æµ‹è¯•ç»“æœ: {json.dumps(result, indent=2, ensure_ascii=False)}")
            else:
                print(f"âœ— OpenAIåµŒå…¥æ¨¡å‹è¿æ¥æµ‹è¯•å¤±è´¥: {response.text}")
        except Exception as e:
            print(f"âœ— OpenAIåµŒå…¥æ¨¡å‹è¿æ¥æµ‹è¯•å¼‚å¸¸: {e}")
    
    # æµ‹è¯•æ— APIå¯†é’¥çš„æƒ…å†µ
    print("\n5. æµ‹è¯•æ— APIå¯†é’¥çš„æƒ…å†µ...")
    try:
        llm_config = {
            "provider": "siliconflow",
            "model": "Qwen/Qwen2-7B-Instruct",
            "temperature": 0.7,
            "max_tokens": 1000
        }
        response = requests.post(f"{base_url}/config/test/llm", json=llm_config)
        print(f"çŠ¶æ€ç : {response.status_code}")
        if response.status_code == 200:
            result = response.json()
            print(f"æµ‹è¯•ç»“æœ: {json.dumps(result, indent=2, ensure_ascii=False)}")
        else:
            print(f"æµ‹è¯•å¤±è´¥: {response.text}")
    except Exception as e:
        print(f"æµ‹è¯•å¼‚å¸¸: {e}")
    
    print("\nğŸ‰ çœŸå®æ¨¡å‹è¿æ¥æµ‹è¯•å®Œæˆ!")
    print("\nğŸ’¡ ä½¿ç”¨è¯´æ˜:")
    print("1. è®¾ç½®ç¯å¢ƒå˜é‡:")
    print("   export SILICONFLOW_API_KEY='your-siliconflow-key'")
    print("   export OPENAI_API_KEY='your-openai-key'")
    print("2. é‡æ–°è¿è¡Œæµ‹è¯•ä»¥éªŒè¯çœŸå®è¿æ¥")

if __name__ == "__main__":
    test_real_connections()